## Step 2: Enhanced Concurrency - Detailed Plan

**Goal:** Benchmark `ThreadPoolExecutor` vs. `ProcessPoolExecutor` for pipeline passes and abstract the choice behind a configuration flag (). Use the current runtime of ~16.46s on the sample data with `ThreadPoolExecutor` as a baseline.

### 1. Benchmarking Strategy

* **Objective:** Quantify performance differences between thread-based and process-based concurrency for pipeline stages.
* **Identify Potential CPU Bottlenecks:**
    * Pass 0 (`crop.py`): Mixed I/O (TIFF read) and CPU (NumPy/SciPy for MIPs, stats, slope).
    * Pass 1 (`limits.py`): Mixed I/O (TIFF read) and CPU (NumPy/SciPy for cropping, stats, limits). Becomes CPU-bound after initial I/O.
    * Pass 2 (`processing.py`): CPU-bound (NumPy stretch, PIL/NumPy tiling) and I/O/CPU-bound (WebP save).
* **Methodology:**
    * **(Optional) Add Granular Timing:** Modify `core.py` to time each major pass (`_prepare_tasks_and_layout`, `limits.calculate_global_limits`, `processing.execute_processing_pass`). *Relates to Roadmap Step 5.*
    * **Run Baseline:** Execute with `ThreadPoolExecutor` (current default) using `--threads N`. Record total and per-pass times.
        ```bash
        pixelpacker --output ./benchmark_thread --threads <N>
        ```
    * **Modify for ProcessPoolExecutor:** Temporarily replace `ThreadPoolExecutor` with `ProcessPoolExecutor` in `crop.py`, `limits.py`, and `processing.py`.
    * **Run Process Benchmark:** Execute with `ProcessPoolExecutor` using `--threads N`. Record times.
        ```bash
        # (After temporary code modification)
        pixelpacker --output ./benchmark_process --threads <N>
        ```
    * **Analyze:** Compare total and per-pass times. Note improvements, regressions, and any pickling errors encountered with `ProcessPoolExecutor`.

### 2. Implementation: Abstracting Executor Choice

* **Configuration (`src/pixelpacker/data_models.py`):**
    * Add `executor_type` field to `PreprocessingConfig`:
        ```python
        from typing import Literal # Add this import

        @dataclass
        class PreprocessingConfig:
            # ... other fields ...
            executor_type: Literal["thread", "process"] = "thread"
        ```
* **CLI Flag (`src/pixelpacker/cli.py`):**
    * Define an Enum for choices:
        ```python
        import enum
        class ExecutorChoice(str, enum.Enum):
            thread = "thread"
            process = "process"
        ```
    * Add a Typer option:
        ```python
        executor: Annotated[ExecutorChoice, typer.Option(
            "--executor",
            case_sensitive=False,
            help="Concurrency execution model ('thread' or 'process').",
        )] = ExecutorChoice.thread,
        ```
    * Update `args_dict` creation in `cli.py` to pass `executor.value`.
    * Update `_setup_configuration` in `core.py` to handle and store the `executor_type`.
* **Executor Selection Logic (Recommended: Centralized Helper):**
    * Create a context manager in `src/pixelpacker/utils.py` (or `core.py`):
        ```python
        # Example in utils.py
        from concurrent.futures import Executor, ThreadPoolExecutor, ProcessPoolExecutor
        from contextlib import contextmanager
        from typing import Iterator # Add this import
        from .data_models import PreprocessingConfig # Assuming data_models is in the same dir or adjust path
        from .utils import log # Assuming log is defined in utils

        @contextmanager
        def get_executor(config: PreprocessingConfig) -> Iterator[Executor]:
            executor_instance: Optional[Executor] = None
            ExecutorClass = ThreadPoolExecutor # Default
            executor_name = "thread"

            if config.executor_type == "process":
                log.info(f"Creating ProcessPoolExecutor (max_workers={config.max_threads})")
                ExecutorClass = ProcessPoolExecutor
                executor_name = "process"
                # Optional: Add warning about overhead/pickling
            else:
                log.info(f"Creating ThreadPoolExecutor (max_workers={config.max_threads})")

            try:
                # Consider adding thread_name_prefix back if using ThreadPoolExecutor
                executor_instance = ExecutorClass(max_workers=config.max_threads)
                yield executor_instance
            finally:
                if executor_instance:
                    log.debug(f"Shutting down {executor_name} executor.")
                    # Ensure tasks complete before exiting context
                    executor_instance.shutdown(wait=True)
        ```
    * Use this context manager within the orchestrator functions in `crop.py`, `limits.py`, and `processing.py`:
        ```python
        # Example in limits.py
        from ..utils import get_executor # Adjust import as needed

        def calculate_global_limits(...):
            # ... setup ...
            with get_executor(config) as executor:
                futures = { executor.submit(...) : task for task in tasks }
                # ... process futures ...
            # ... rest of function ...
        ```

### 3. Documentation

* Update `README.md`:
    * Add `--executor [thread|process]` to the CLI Options table.
    * Briefly explain the difference and suggest when to use `process`.